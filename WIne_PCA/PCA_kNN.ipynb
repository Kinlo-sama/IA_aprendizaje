{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from ucimlrepo import fetch_ucirepo \n",
    "    import pandas as pd\n",
    "    import numpy as np  \n",
    "    from numpy.fft import fft\n",
    "    import random \n",
    "    from scipy.stats import mode\n",
    "    import glob\n",
    "    import os \n",
    "    import matplotlib.pyplot as plt\n",
    "    from rich import print as rprint\n",
    "    import sklearn \n",
    "    import librosa \n",
    "    import json \n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'ucimlrepo', 'pandas', 'numpy', 'scipy', 'matplotlib', 'librosa', 'rich', 'sklearn', 'librosa' ])\n",
    "    # Una vez instaladas las bibliotecas, intenta importarlas nuevamente\n",
    "    from ucimlrepo import fetch_ucirepo \n",
    "    import pandas as pd\n",
    "    import numpy as np  \n",
    "    from numpy.fft import fft\n",
    "    from scipy.stats import mode\n",
    "    import librosa \n",
    "    import json \n",
    "\n",
    "#Aumentar visualización de datos ya que notebok limita el numero de columnas a observar \n",
    "np.set_printoptions(threshold=np.inf, linewidth=np.inf)\n",
    "#Aumentar visualización de datos ya que notebok limita el numero de columnas a observar \n",
    "np.set_printoptions(threshold=np.inf, linewidth=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wine_raw = pd.read_csv(\"./wine_data.csv\")\n",
    "data_wine_raw\n",
    "#Extracción de caracteristicas\n",
    "data_wine_nc = data_wine_raw.iloc[:,1:]\n",
    "#Extracción de labels\n",
    "labels = data_wine_raw.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_PCA_percent(percent_query) -> tuple:\n",
    "    #Datos\n",
    "\n",
    "    #-Query\n",
    "    nume_sample_query = int((len(data_wine_nc)) * percent_query/100)\n",
    "    query_index_samples = random.sample(list(range(0,178)), nume_sample_query)\n",
    "    query_index_samples.sort()\n",
    "    query_samples = data_wine_nc.iloc[query_index_samples]\n",
    "\n",
    "    #-Training samples\n",
    "    training_samples = data_wine_nc.drop(query_index_samples)\n",
    "\n",
    "    #-Labels \n",
    "    query_samples_labels = labels[query_index_samples]\n",
    "    training_samples_labels = labels.drop(query_index_samples) \n",
    "\n",
    "    #Normalización \n",
    "\n",
    "    #Creamos una matriz (filas_training, 13)\n",
    "    promedios_training = np.array(training_samples.mean())\n",
    "    promedios_training_t = np.tile(promedios_training, (training_samples.shape[0], 1))\n",
    "    promedios_training_q = np.tile(promedios_training, (query_samples.shape[0],1))\n",
    "\n",
    "    #Creamos una matriz diagonal con los valores de las desviaciones std de cada fila \n",
    "    std_training = np.array(training_samples.std()) ** -1\n",
    "    dig_std_training = np.eye(len(std_training))\n",
    "    np.fill_diagonal(dig_std_training, std_training)\n",
    "\n",
    "    #Normalización para training ---------------------------------------------\n",
    "    #Aplicando primero -> x - µ = ß\n",
    "    normal_training = training_samples - promedios_training_t\n",
    "    #Luego ł = ß / σ\n",
    "    #Para ello ł se multiplicara por una matriz diagonal en donde la diagonal contiene sus desviaciones std\n",
    "    normal_training = (normal_training @ dig_std_training).T\n",
    "\n",
    "    #Normalización para query ------------------------------------------------\n",
    "    #Aplicando primero -> x - µ = ß\n",
    "    normal_query = query_samples - promedios_training_q\n",
    "    #Luego ł = ß / σ\n",
    "    #Para ello ł se multiplicara por una matriz diagonal en donde la diagonal contiene sus desviaciones std\n",
    "    normal_query = (normal_query @ dig_std_training)\n",
    "\n",
    "    #PCA--------------------------------------------------------------------\n",
    "    #Dimension wine_normal_query -> (35, 13)\n",
    "    matrix_cov = np.cov(normal_training)\n",
    "    eigen_val, eigen_vec = np.linalg.eig(matrix_cov)\n",
    "    ind = np.argsort( eigen_val)[::-1]\n",
    "    eigen_vec_ord = eigen_vec[:, ind]\n",
    "    eigenvectores_visualizar = [0, 1, 2]\n",
    "    matriz_de_transformacion = eigen_vec_ord[:,eigenvectores_visualizar]\n",
    "    #La matriz_de_transformacion tiene las dimensiones de -> (13,3)\n",
    "    data_reducido_q = normal_query @ matriz_de_transformacion\n",
    "    normal_training = normal_training.T\n",
    "    data_reducido_t = normal_training @ matriz_de_transformacion\n",
    "    return data_reducido_q, query_samples_labels, data_reducido_t, training_samples_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruebaI(query_samples,training_samples,query_samples_label,training_samples_label, k_s = 3) -> float:\n",
    "    k = k_s                               \n",
    "    \n",
    "    #Elementos en total de la query\n",
    "    totalQ = len(query_samples)\n",
    "    totalT = len(training_samples)\n",
    "    size_q  = len(query_samples)                                                        #Size de query\n",
    "    k_DI = []  \n",
    "    cont_Error = 0\n",
    "    #Algoritmo kNN --------------------------------  \n",
    "    # query_samples_label.iloc[0]                                   #Aqui se almacenan las k distancias mas pequeñas                                                                          #\n",
    "\n",
    "    for j in range(size_q):  \n",
    "        #print(j)                                                        #iteramos por todos los elementos de la query\n",
    "        Q = np.tile(query_samples.iloc[j,:],(training_samples.shape[0],1))              #Igual que 'repmat'\n",
    "        Z = Q - training_samples                                                        \n",
    "        \n",
    "        S_with_garbage = Z @ Z.T                                                        #puede usar tambien np.dot(m1,m2)\n",
    "        distancia_S = np.diag(S_with_garbage) ** (1 / 2)                                #Obtener la diagonal y elevar sus elem a 1/2\n",
    "        \n",
    "        sort_index = np.argsort(distancia_S)                                            #Obtener los indices ordenados\n",
    "        \n",
    "        k_index = sort_index[:k]                                                        #Seleccionamos los k primeros\n",
    "        k_dis = distancia_S[k_index]                                                    #Almacenamos las k distancias minimas\n",
    "\n",
    "        mode_k_dis = mode(k_dis)[0]                                                     #mode retorna (moda, repeticiones)\n",
    "        index_mode = np.where(distancia_S == mode_k_dis)[0][0]                        #buscamos indice en distancia_S de mode_k_dis\n",
    "        k_DI.append(index_mode) \n",
    "        if query_samples_label.iloc[j] != training_samples_label.iloc[index_mode]:\n",
    "            #print(\"Error:------------------------\")\n",
    "            #print(query_samples_label.iloc[j],\"--\",training_samples_label.iloc[index_mode])\n",
    "            cont_Error += 1\n",
    "        #else:\n",
    "            #print(\"Success:------------------------\")\n",
    "            #print(query_samples_label.iloc[j],\"--\",training_samples_label.iloc[index_mode])\n",
    "\n",
    "\n",
    "    #print(cont_Error)\n",
    "    percent_success = (totalQ - cont_Error) * (100 / totalQ)\n",
    "    return percent_success\n",
    "    #return (totalQ, totalT, k, cont_Error, percent_success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambiar el rango a n pruebas \n",
    "porcentajes = []\n",
    "for _ in range(10):\n",
    "    q, lbq, t, lbt = cal_PCA_percent(30)\n",
    "    porcentajes.append(pruebaI(q, t, lbq, lbt))#q,t,ql,tl, k_s = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.77358490566039"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(porcentajes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
