{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from ucimlrepo import fetch_ucirepo \n",
    "    import pandas as pd\n",
    "    import numpy as np  \n",
    "    from numpy.fft import fft\n",
    "    import random \n",
    "    from scipy.stats import mode\n",
    "    import glob\n",
    "    import os \n",
    "    import matplotlib.pyplot as plt\n",
    "    from rich import print as rprint\n",
    "    import sklearn \n",
    "    import librosa \n",
    "    import json \n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'ucimlrepo', 'pandas', 'numpy', 'scipy', 'matplotlib', 'librosa', 'rich', 'sklearn', 'librosa' ])\n",
    "    # Una vez instaladas las bibliotecas, intenta importarlas nuevamente\n",
    "    from ucimlrepo import fetch_ucirepo \n",
    "    import pandas as pd\n",
    "    import numpy as np  \n",
    "    from numpy.fft import fft\n",
    "    from scipy.stats import mode\n",
    "    import librosa \n",
    "    import json \n",
    "\n",
    "#Aumentar visualización de datos ya que notebok limita el numero de columnas a observar \n",
    "np.set_printoptions(threshold=np.inf, linewidth=np.inf)\n",
    "#Aumentar visualización de datos ya que notebok limita el numero de columnas a observar \n",
    "np.set_printoptions(threshold=np.inf, linewidth=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wine_raw = pd.read_csv(\"./wine_data.csv\")\n",
    "data_wine_raw\n",
    "#Extracción de caracteristicas\n",
    "data_wine_nc = data_wine_raw.iloc[:,1:]\n",
    "#Extracción de labels\n",
    "labels = data_wine_raw.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "def cal_PCA_percent(percent_query) -> tuple:\n",
    "    #Datos\n",
    "\n",
    "    #-Query\n",
    "    nume_sample_query = int((len(data_wine_nc)) * percent_query/100)\n",
    "    query_index_samples = random.sample(list(range(0,178)), nume_sample_query)\n",
    "    query_index_samples.sort()\n",
    "    query_samples = data_wine_nc.iloc[query_index_samples]\n",
    "\n",
    "    #-Training samples\n",
    "    training_samples = data_wine_nc.drop(query_index_samples)\n",
    "\n",
    "    #-Labels \n",
    "    query_samples_labels = labels[query_index_samples]\n",
    "    training_samples_labels = labels.drop(query_index_samples) \n",
    "\n",
    "    #Normalización \n",
    "\n",
    "    #Creamos una matriz (filas_training, 13)\n",
    "    promedios_training = np.array(training_samples.mean())\n",
    "    promedios_training_t = np.tile(promedios_training, (training_samples.shape[0], 1))\n",
    "    promedios_training_q = np.tile(promedios_training, (query_samples.shape[0],1))\n",
    "\n",
    "    #Creamos una matriz diagonal con los valores de las desviaciones std de cada fila \n",
    "    std_training = np.array(training_samples.std()) ** -1\n",
    "    dig_std_training = np.eye(len(std_training))\n",
    "    np.fill_diagonal(dig_std_training, std_training)\n",
    "\n",
    "    #Normalización para training ---------------------------------------------\n",
    "    #Aplicando primero -> x - µ = ß\n",
    "    normal_training = training_samples - promedios_training_t\n",
    "    #Luego ł = ß / σ\n",
    "    #Para ello ł se multiplicara por una matriz diagonal en donde la diagonal contiene sus desviaciones std\n",
    "    normal_training = (normal_training @ dig_std_training).T\n",
    "\n",
    "    #Normalización para query ------------------------------------------------\n",
    "    #Aplicando primero -> x - µ = ß\n",
    "    normal_query = query_samples - promedios_training_q\n",
    "    #Luego ł = ß / σ\n",
    "    #Para ello ł se multiplicara por una matriz diagonal en donde la diagonal contiene sus desviaciones std\n",
    "    normal_query = (normal_query @ dig_std_training)\n",
    "\n",
    "    #PCA--------------------------------------------------------------------\n",
    "    #Dimension wine_normal_query -> (35, 13)\n",
    "    start = time.time()\n",
    "    matrix_cov = np.cov(normal_training)\n",
    "    eigen_val, eigen_vec = np.linalg.eig(matrix_cov)\n",
    "        \n",
    "    print(\"Time Consumed\")\n",
    "    print(\"% s seconds\" % (time.time() - start))\n",
    "    ind = np.argsort( eigen_val)[::-1]\n",
    "    eigen_vec_ord = eigen_vec[:, ind]\n",
    "    eigenvectores_visualizar = [0, 1, 2]\n",
    "    matriz_de_transformacion = eigen_vec_ord[:,eigenvectores_visualizar]\n",
    "    #La matriz_de_transformacion tiene las dimensiones de -> (13,3)\n",
    "    data_reducido_q = normal_query @ matriz_de_transformacion\n",
    "    normal_training = normal_training.T\n",
    "    data_reducido_t = normal_training @ matriz_de_transformacion\n",
    "    return data_reducido_q, query_samples_labels, data_reducido_t, training_samples_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruebaI(query_samples,training_samples,query_samples_label,training_samples_label, k_s = 3) -> float:\n",
    "    k = k_s                               \n",
    "    \n",
    "    #Elementos en total de la query\n",
    "    totalQ = len(query_samples)\n",
    "    totalT = len(training_samples)\n",
    "    size_q  = len(query_samples)                                                        #Size de query\n",
    "    k_DI = []  \n",
    "    cont_Error = 0\n",
    "    #Algoritmo kNN --------------------------------  \n",
    "    # query_samples_label.iloc[0]                                   #Aqui se almacenan las k distancias mas pequeñas                                                                          #\n",
    "\n",
    "    for j in range(size_q):  \n",
    "        #print(j)                                                        #iteramos por todos los elementos de la query\n",
    "        Q = np.tile(query_samples.iloc[j,:],(training_samples.shape[0],1))              #Igual que 'repmat'\n",
    "        Z = Q - training_samples                                                        \n",
    "        \n",
    "        S_with_garbage = Z @ Z.T                                                        #puede usar tambien np.dot(m1,m2)\n",
    "        distancia_S = np.diag(S_with_garbage) ** (1 / 2)                                #Obtener la diagonal y elevar sus elem a 1/2\n",
    "        \n",
    "        sort_index = np.argsort(distancia_S)                                            #Obtener los indices ordenados\n",
    "        \n",
    "        k_index = sort_index[:k]                                                        #Seleccionamos los k primeros\n",
    "        k_dis = distancia_S[k_index]                                                    #Almacenamos las k distancias minimas\n",
    "\n",
    "        mode_k_dis = mode(k_dis)[0]                                                     #mode retorna (moda, repeticiones)\n",
    "        index_mode = np.where(distancia_S == mode_k_dis)[0][0]                        #buscamos indice en distancia_S de mode_k_dis\n",
    "        k_DI.append(index_mode) \n",
    "        if query_samples_label.iloc[j] != training_samples_label.iloc[index_mode]:\n",
    "            #print(\"Error:------------------------\")\n",
    "            #print(query_samples_label.iloc[j],\"--\",training_samples_label.iloc[index_mode])\n",
    "            cont_Error += 1\n",
    "        #else:\n",
    "            #print(\"Success:------------------------\")\n",
    "            #print(query_samples_label.iloc[j],\"--\",training_samples_label.iloc[index_mode])\n",
    "\n",
    "\n",
    "    #print(cont_Error)\n",
    "    percent_success = (totalQ - cont_Error) * (100 / totalQ)\n",
    "    return percent_success\n",
    "    #return (totalQ, totalT, k, cont_Error, percent_success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambiar el rango a n pruebas \n",
    "porcentajes = []\n",
    "for _ in range(10):\n",
    "    q, lbq, t, lbt = cal_PCA_percent(30)\n",
    "    porcentajes.append(pruebaI(q, t, lbq, lbt))#q,t,ql,tl, k_s = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.77358490566039"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(porcentajes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Consumed\n",
      "0.0014977455139160156 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(            0         1         2\n",
       " 0   -3.240281 -1.536973 -0.174601\n",
       " 10  -3.413953 -1.448675 -0.484242\n",
       " 36  -1.350165 -0.719553  0.474267\n",
       " 41  -0.618913 -0.230936 -0.838152\n",
       " 45  -1.039573 -1.821404 -0.006682\n",
       " 54  -2.076537 -1.070059 -0.948497\n",
       " 56  -2.665564 -1.513720 -0.635773\n",
       " 61   1.833113  0.825954 -1.434020\n",
       " 83   2.523412  0.064445  0.473256\n",
       " 86   0.721429  2.175545  0.832163\n",
       " 92   1.864677  1.523334 -0.032480\n",
       " 124 -1.013152  1.378736  1.245827\n",
       " 125  0.045033  2.066703  0.414619\n",
       " 140  2.769369 -0.245669  0.667970\n",
       " 148  2.836274 -1.521053 -0.493744\n",
       " 150  2.371619 -2.255320  0.407115\n",
       " 159  1.610361 -2.404901  0.447784,\n",
       " 0      1\n",
       " 10     1\n",
       " 36     1\n",
       " 41     1\n",
       " 45     1\n",
       " 54     1\n",
       " 56     1\n",
       " 61     2\n",
       " 83     2\n",
       " 86     2\n",
       " 92     2\n",
       " 124    2\n",
       " 125    2\n",
       " 140    3\n",
       " 148    3\n",
       " 150    3\n",
       " 159    3\n",
       " Name: class_label, dtype: int64,\n",
       "             0         1         2\n",
       " 1   -2.150271  0.250461 -1.983409\n",
       " 2   -2.490356 -1.156119  0.854712\n",
       " 3   -3.648801 -2.874296 -0.272488\n",
       " 4   -0.990048 -0.929837  1.999006\n",
       " 5   -2.954434 -2.252061 -0.642780\n",
       " ..        ...       ...       ...\n",
       " 173  3.446566 -2.170612 -0.359517\n",
       " 174  2.638287 -1.718332  0.190451\n",
       " 175  2.769624 -2.701766 -0.905706\n",
       " 176  2.443029 -2.258967 -0.473486\n",
       " 177  3.247358 -2.719717  0.961274\n",
       " \n",
       " [161 rows x 3 columns],\n",
       " 1      1\n",
       " 2      1\n",
       " 3      1\n",
       " 4      1\n",
       " 5      1\n",
       "       ..\n",
       " 173    3\n",
       " 174    3\n",
       " 175    3\n",
       " 176    3\n",
       " 177    3\n",
       " Name: class_label, Length: 161, dtype: int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todo = cal_PCA_percent(10)\n",
    "todo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
