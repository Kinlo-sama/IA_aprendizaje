{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Proyecto_idDrRecursos.ipynb\n",
    "from scipy.sparse.linalg import eigsh\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "Freqs_drone = pd.read_json(\"Seleccion/Frecuencias/colFreqs1500.json\")\n",
    "label_drone = pd.read_csv(\"Seleccion/Frecuencias/labelFreqs1500.csv\")\n",
    "#Configuraciones para no truncar la salida  ***************\n",
    "pd.set_option('display.max_rows', None)\n",
    "#Porcentaje 50 \n",
    "percent_query = 10\n",
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos \n",
    "\n",
    "#Query\n",
    "nume_samples_query = int((len(Freqs_drone) * percent_query)/100)                       #Numero de muestras con respecto al porcentanje         \n",
    "query_index_samples = random.sample(list(range(0,400)),nume_samples_query)          #Escogemos los indices de query aleatoriamente sin remplazo\n",
    "query_index_samples.sort()                                                          #Ordenamos \n",
    "query_samples = Freqs_drone.iloc[query_index_samples]                                  #seleccionamos de data_num con respecto a los indices encontrados \n",
    "#Training\n",
    "#Agregar inplace como True para eliminar de la original \n",
    "training_samples = Freqs_drone.drop(query_index_samples)                               #Escogemos los indices faltantes\n",
    "\n",
    "#Label \n",
    "query_samples_label = label_drone.iloc[query_index_samples]                          #iloc -> [] usando los indices antes encontrados para query\n",
    "training_samples_label = label_drone.drop(query_index_samples)                       #Escogemos los indices faltantes \n",
    "\n",
    "#Elementos en total \n",
    "total = len(query_samples)\n",
    "\n",
    "def PCA():    \n",
    "\n",
    "\n",
    "    #Normalización \n",
    "\n",
    "    #Creamos una matriz (filas_training, 13)\n",
    "    promedios_training = np.array(training_samples.mean())\n",
    "    promedios_training_t = np.tile(promedios_training, (training_samples.shape[0], 1))\n",
    "    promedios_training_q = np.tile(promedios_training, (query_samples.shape[0],1))\n",
    "\n",
    "    #Creamos una matriz diagonal con los valores de las desviaciones std de cada fila \n",
    "    std_training = np.array(training_samples.std()) ** -1\n",
    "    dig_std_training = np.eye(len(std_training))\n",
    "    np.fill_diagonal(dig_std_training, std_training)\n",
    "\n",
    "\n",
    "    #Normalización para training ---------------------------------------------\n",
    "    #Aplicando primero -> x - µ = ß\n",
    "    normal_training = training_samples - promedios_training_t\n",
    "    #Luego ł = ß / σ\n",
    "    #Para ello ł se multiplicara por una matriz diagonal en donde la diagonal contiene sus desviaciones std\n",
    "    normal_training = (normal_training @ dig_std_training).T\n",
    "\n",
    "\n",
    "    #Normalización para query ------------------------------------------------\n",
    "    #Aplicando primero -> x - µ = ß\n",
    "    normal_query = query_samples - promedios_training_q\n",
    "    #Luego ł = ß / σ\n",
    "    #Para ello ł se multiplicara por una matriz diagonal en donde la diagonal contiene sus desviaciones std\n",
    "    normal_query = (normal_query @ dig_std_training)\n",
    "\n",
    "    start = time.time()\n",
    "    #PCA--------------------------------------------------------------------\n",
    "    #Dimension wine_normal_query -> (35, 13)\n",
    "\n",
    "    matrix_cov = np.cov(normal_training)\n",
    "    eigen_val, eigen_vec = np.linalg.eig(matrix_cov)\n",
    "    \n",
    "    ind = np.argsort( eigen_val)[::-1]\n",
    "    eigen_vec_ord = eigen_vec[:, ind]\n",
    "    eigenvectores_visualizar = [a for a in range(30)]\n",
    "    matriz_de_transformacion = eigen_vec_ord[:,eigenvectores_visualizar]\n",
    "    \n",
    "    #La matriz_de_transformacion tiene las dimensiones de -> (13,3)\n",
    "    normal_training = normal_training.T\n",
    "    data_reducido_t = normal_training @ matriz_de_transformacion\n",
    "\n",
    "    data_reducido_q = normal_query @ matriz_de_transformacion\n",
    "    return data_reducido_q, data_reducido_t\n",
    "\n",
    "query_samples, training_samples = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruebaI():\n",
    "\n",
    "\n",
    "    #Elementos en total de la query\n",
    "    totalQ = len(query_samples)\n",
    "    totalT = len(training_samples)\n",
    "    size_q  = len(query_samples)                                                        #Size de query\n",
    "    k_DI = []  \n",
    "    cont_Error = 0\n",
    "    #Algoritmo kNN --------------------------------  \n",
    "    # query_samples_label.iloc[0]                                   #Aqui se almacenan las k distancias mas pequeñas                                                                          #\n",
    "\n",
    "    for j in range(size_q):  \n",
    "        #print(j)                                                        #iteramos por todos los elementos de la query\n",
    "        Q = np.tile(query_samples.iloc[j,:],(training_samples.shape[0],1))              #Igual que 'repmat'\n",
    "        Z = Q - training_samples                                                        \n",
    "        \n",
    "        S_with_garbage = Z @ Z.T                                                        #puede usar tambien np.dot(m1,m2)\n",
    "        distancia_S = np.diag(S_with_garbage) ** (1 / 2)                                #Obtener la diagonal y elevar sus elem a 1/2\n",
    "        \n",
    "        sort_index = np.argsort(distancia_S)                                            #Obtener los indices ordenados\n",
    "        \n",
    "        k_index = sort_index[:k]                                                        #Seleccionamos los k primeros\n",
    "        k_dis = distancia_S[k_index]                                                    #Almacenamos las k distancias minimas\n",
    "\n",
    "        mode_k_dis = mode(k_dis, keepdims=False)[0]                                                     #mode retorna (moda, repeticiones)\n",
    "        index_mode = np.where(distancia_S == mode_k_dis)[0][0]                        #buscamos indice en distancia_S de mode_k_dis\n",
    "        k_DI.append(index_mode) \n",
    "        if query_samples_label.iloc[j,0] != training_samples_label.iloc[index_mode,0]:\n",
    "            #print(\"Error:------------------------\")\n",
    "            #print(query_samples_label.iloc[j],\"--\",training_samples_label.iloc[index_mode])\n",
    "            cont_Error += 1\n",
    "        #else:\n",
    "            #print(\"Success:------------------------\")\n",
    "            #print(query_samples_label.iloc[j],\"--\",training_samples_label.iloc[index_mode])\n",
    "\n",
    "\n",
    "    #print(cont_Error)\n",
    "    percent_success = (totalQ - cont_Error) * (100 / totalQ)\n",
    "    #return (totalQ, totalT, k, cont_Error, percent_success)\n",
    "\n",
    "    percent_success = (total - cont_Error) * (100 / total)\n",
    "    return percent_success\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruebaIsin():\n",
    "    #Datos \n",
    "    #Query\n",
    "    nume_samples_query = int((len(Freqs_drone) * percent_query)/100)                       #Numero de muestras con respecto al porcentanje         \n",
    "    query_index_samples = random.sample(list(range(0,400)),nume_samples_query)          #Escogemos los indices de query aleatoriamente sin remplazo\n",
    "    query_index_samples.sort()                                                          #Ordenamos \n",
    "    query_samples = Freqs_drone.iloc[query_index_samples]                                  #seleccionamos de data_num con respecto a los indices encontrados \n",
    "    #Training\n",
    "    #Agregar inplace como True para eliminar de la original \n",
    "    training_samples = Freqs_drone.drop(query_index_samples)                               #Escogemos los indices faltantes\n",
    "\n",
    "    #Label \n",
    "    query_samples_label = label_drone.iloc[query_index_samples]                          #iloc -> [] usando los indices antes encontrados para query\n",
    "    training_samples_label = label_drone.drop(query_index_samples)                       #Escogemos los indices faltantes \n",
    "\n",
    "    #Elementos en total de la query\n",
    "    totalQ = len(query_samples)\n",
    "    totalT = len(training_samples)\n",
    "    size_q  = len(query_samples)                                                        #Size de query\n",
    "    k_DI = []  \n",
    "    cont_Error = 0\n",
    "    #Algoritmo kNN --------------------------------  \n",
    "    # query_samples_label.iloc[0]                                   #Aqui se almacenan las k distancias mas pequeñas                                                                          #\n",
    "    total = len(query_samples)\n",
    "    for j in range(size_q):  \n",
    "        #print(j)                                                        #iteramos por todos los elementos de la query\n",
    "        Q = np.tile(query_samples.iloc[j,:],(training_samples.shape[0],1))              #Igual que 'repmat'\n",
    "        Z = Q - training_samples                                                        \n",
    "        \n",
    "        S_with_garbage = Z @ Z.T                                                        #puede usar tambien np.dot(m1,m2)\n",
    "        distancia_S = np.diag(S_with_garbage) ** (1 / 2)                                #Obtener la diagonal y elevar sus elem a 1/2\n",
    "        \n",
    "        sort_index = np.argsort(distancia_S)                                            #Obtener los indices ordenados\n",
    "        \n",
    "        k_index = sort_index[:k]                                                        #Seleccionamos los k primeros\n",
    "        k_dis = distancia_S[k_index]                                                    #Almacenamos las k distancias minimas\n",
    "\n",
    "        mode_k_dis = mode(k_dis, keepdims=False)[0]                                                     #mode retorna (moda, repeticiones)\n",
    "        index_mode = np.where(distancia_S == mode_k_dis)[0][0]                        #buscamos indice en distancia_S de mode_k_dis\n",
    "        k_DI.append(index_mode) \n",
    "        if query_samples_label.iloc[j,0] != training_samples_label.iloc[index_mode,0]:\n",
    "            #print(\"Error:------------------------\")\n",
    "            #print(query_samples_label.iloc[j],\"--\",training_samples_label.iloc[index_mode])\n",
    "            cont_Error += 1\n",
    "        #else:\n",
    "            #print(\"Success:------------------------\")\n",
    "            #print(query_samples_label.iloc[j],\"--\",training_samples_label.iloc[index_mode])\n",
    "\n",
    "\n",
    "    #print(cont_Error)\n",
    "    percent_success = (totalQ - cont_Error) * (100 / totalQ)\n",
    "    #return (totalQ, totalT, k, cont_Error, percent_success)\n",
    "\n",
    "    percent_success = (total - cont_Error) * (100 / total)\n",
    "    return percent_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.5\n"
     ]
    }
   ],
   "source": [
    "print(pruebaI())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
