{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracción de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random \n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos globales\n",
    "Freqs_drone = pd.read_json(\"Seleccion/colFreqs.json\")\n",
    "label_drone = pd.read_csv(\"Seleccion/labelFreqs.csv\")\n",
    "#Configuraciones para no truncar la salida  ***************\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruebaI(k_s = 3, perc = 30) -> tuple:\n",
    "    percent_query = perc\n",
    "    k = k_s\n",
    "    #Datos ------------------------------------------\n",
    "    #Query\n",
    "    nume_samples_query = int((len(Freqs_drone) * percent_query)/100)                       #Numero de muestras con respecto al porcentanje         \n",
    "    query_index_samples = random.sample(list(range(0,400)),nume_samples_query)          #Escogemos los indices de query aleatoriamente sin remplazo\n",
    "    query_index_samples.sort()                                                          #Ordenamos \n",
    "    query_samples = Freqs_drone.iloc[query_index_samples]                                  #seleccionamos de data_num con respecto a los indices encontrados \n",
    "    #Training\n",
    "    #Agregar inplace como True para eliminar de la original \n",
    "    training_samples = Freqs_drone.drop(query_index_samples)                               #Escogemos los indices faltantes\n",
    "\n",
    "    #Label \n",
    "    query_samples_label = label_drone.iloc[query_index_samples]                          #iloc -> [] usando los indices antes encontrados para query\n",
    "    training_samples_label = label_drone.drop(query_index_samples)                       #Escogemos los indices faltantes \n",
    "\n",
    "    #Elementos en total de la query\n",
    "    totalQ = len(query_samples)\n",
    "    totalT = len(training_samples)\n",
    "    size_q  = len(query_samples)                                                        #Size de query\n",
    "    k_DI = []  \n",
    "    cont_Error = 0\n",
    "    #Algoritmo kNN --------------------------------                                                                     #Aqui se almacenan las k distancias mas pequeñas                                                                          #\n",
    "    for j in range(size_q):                                                             #iteramos por todos los elementos de la query\n",
    "        Q = np.tile(query_samples.iloc[j,:],(training_samples.shape[0],1))              #Igual que 'repmat'\n",
    "        Z = Q - training_samples                                                        #\n",
    "        \n",
    "        S_with_garbage = Z @ Z.T                                                        #puede usar tambien np.dot(m1,m2)\n",
    "        distancia_S = np.diag(S_with_garbage) ** (1 / 2)                                #Obtener la diagonal y elevar sus elem a 1/2\n",
    "        \n",
    "        sort_index = np.argsort(distancia_S)                                            #Obtener los indices ordenados\n",
    "        \n",
    "        k_index = sort_index[:k]                                                        #Seleccionamos los k primeros\n",
    "        k_dis = distancia_S[k_index]                                                    #Almacenamos las k distancias minimas\n",
    "\n",
    "        mode_k_dis = mode(k_dis)[0]                                                     #mode retorna (moda, repeticiones)\n",
    "        index_mode = np.where(distancia_S == mode_k_dis)[0][0]                          #buscamos indice en distancia_S de mode_k_dis\n",
    "        k_DI.append(index_mode) \n",
    "        if query_samples_label.iloc[j, 0] != training_samples_label.iloc[index_mode, 0]:\n",
    "            cont_Error += 1\n",
    "\n",
    "    percent_success = (totalQ - cont_Error) * (100 / totalQ)\n",
    "\n",
    "    return percent_query, totalQ, totalT, k, cont_Error, percent_success, \n",
    "\n",
    "data = []\n",
    "for _ in range(1000):\n",
    "    pq, tQ, tT, k, e, p = pruebaI(k_s= 5,perc= 40)\n",
    "    data.append([pq, tQ, tT,k , e, p])\n",
    "\n",
    "data_DF = pd.DataFrame(data, columns=[\"Porcentaje Query\", \"Total Query\", \"Total Training\", \"k\", \"Error\", \"Porcentaje\"])\n",
    "ruta = f\"Seleccion/porcentajeExitok5p40.csv\"\n",
    "data_DF.to_csv(ruta, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
